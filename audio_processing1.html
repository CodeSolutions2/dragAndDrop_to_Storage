<!DOCTYPE html>
<html>
<head></head>
<body>

<button id="audio_to_timeseries" onclick="audio_to_timeseries()" style="display:block;">audio_to_timeseries</button>
	
<button id="audio_to_frequency_domain" onclick="audio_to_frequency_domain()" style="display:block;">audio_to_frequency_domain</button>

<button id="audio_to_spectrogram" onclick="audio_to_spectrogram()" style="display:block;">audio_to_spectrogram</button>

<div id="data_display" style="display:block; text-align: left; width: 600px;">


 
<!-- --------------------------------------------------- -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script src='https://d3js.org/d3.v7.min.js'></script>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis@1.5.1/dist/tfjs-vis.umd.min.js" integrity="sha256-qp+MJqHjqWN5L09l6gTFvHhfPvHZAB+c61vy1dOrKs4=" crossorigin="anonymous"></script>
	
<script>

	
// var url = "https://interactive-examples.mdn.mozilla.net/media/cc0-audio/t-rex-roar.mp3";

// -------------------------------------------------
	
var audio_information = {};

async function audio_to_timeseries() {
	
	var url = "https://interactive-examples.mdn.mozilla.net/media/cc0-audio/t-rex-roar.mp3";

	// Create audioElement
	var audioElement = await load_audio_from_url(url, mode="nocors");
  
	// -----------------------------------------------

	// Obtain audio information
	audio_information = await evaluate_audioElement();
	console.log('audio_information: ', audio_information);
	// {channels: channels, fs: fs, time_length: time_length, frameCount: frameCount, time_sample_rate_OR_timePeriod: time_sample_rate_OR_timePeriod}
	
	// -----------------------------------------------
  
	// Fetch binaryString of audio data
	var settings = {
		type : 'GET',
		async: true,
		crossDomain: true,
		xhrFields: {responseType: 'arrayBuffer'},
		dataType: 'binary',
		beforeSend: function(xhr) {xhr.withCredentials = true;},
		success: function(response) { console.log('Success'); },
		error: function(xhr, status, error) { console.log('Error:', error); }
	};
 
	var binaryString = await $.ajax(url, [,settings]).done(function(response) { return response; });
	console.log('binaryString: ', binaryString);

	// -----------------------------------------------

	// Normalize the audio data
	const normalArray_normalized = await decodeAudioData_from_binaryString_to_uint8Array(binaryString);
	const t0 = Array.from({ length: normalArray_normalized.length }, (_, i) => i * audio_information.time_sample_rate_OR_timePeriod);
	
	await plot_line_graph_dataObject(t0, normalArray_normalized, "Timeseries: both channels");
	
	// --------------------

	// Separate the channels of the audio data
	const [channel1, channel2] = await separate_stero_channels(normalArray_normalized)

	console.log('channel1.length : ', channel1.length);
	console.log('channel2.length : ', channel2.length);

	const t1 = Array.from({ length: normalArray_normalized.length }, (_, i) => i * audio_information.time_sample_rate_OR_timePeriod);

	await plot_line_graph_dataObject(t1, channel1, "Timeseries: channel 1");
	await plot_line_graph_dataObject(t1, channel2, "Timeseries: channel 2");

	// --------------------

	// Average the audio data channels
	const x_avg = await channel1.map((val, ind) => { return (val + channel2.at(ind))/2; });
	console.log('x_avg.length : ', x_avg.length);

	await plot_line_graph_dataObject(t1, x_avg, "Timeseries: channels averaged");

	return [t1, x_avg];
}

  
// -------------------------------------------------


async function audio_to_frequency_domain() {
	
	const [t1, x_avg] = await audio_to_timeseries();
	
	// --------------------
  
	// Compute frequency domain
	// const freq_response0 = await DFT(x_avg);
	
	// console.log('freq_response0 : ', freq_response0)
	// Array(19094) [ -72.54431124328238, 32.59010471124958, 14.309210661196708, 3.1579146675091225, 9.462934967315036, 2.315147178945272, 4.04138842725728, 4.199653475746481, 1.076700956385753, 4.018576862667111, … ]
	
	// console.log('freq_response0.length : ', freq_response0.length);	//  19094

	// var freq_arr_char0 = await obtain_array_characteristics(freq_response0);
	// console.log('freq_arr_char0: ', freq_arr_char0);
	
	// OR
	
	var freq_response1 = await tensorflow_FFT(x_avg);
	
	// console.log('freq_response1 : ', freq_response1)
	// Object { kept: false, isDisposedInternal: false, shape: (1) […], dtype: "complex64", size: 19094, strides: [], dataId: {…}, id: 7, rankType: "1", scopeId: 3 }
	// console.log('freq_response1.length : ', freq_response1.length); //  19094

	// Convert tensorflow.js object to array
	const freq_response1_js = freq_response1.arraySync();
	console.log('freq_response1_js.length : ', freq_response1_js.length);

	// var freq_arr_char1 = await obtain_array_characteristics(freq_response1_js);
	// console.log('freq_arr_char1: ', freq_arr_char1);
	// Object { mu: -4407.455090821925, sigma: 1.4284635098976915e-7, max_val: 9990.556640625, min_val: -0.00048828125, max_amp: 9990.556640625 }
	// But, not correct probably because y-axis on plot goes to 40,000
	
	// --------------------

	f = Array.from({ length: freq_response1_js.length }, (_, i) => i * 2 * Math.PI * 1/audio_information.time_sample_rate_OR_timePeriod);
	console.log('f.length : ', f.length);

	// --------------------
	
	// await plot_line_graph_dataObject(f, freq_response0, "Frequency response by hand: Hz");
	// const freq_response_db0 = freq_response0.map((val, ind) => { return 20 * Math.log10(val); });
	// await plot_line_graph_dataObject(f, freq_response_db0, "Frequency response by hand: decibels");
	
	// await plot_line_graph_dataObject(f, freq_response1_js, "Frequency response tf: Hz");
	const freq_response1_js_db = freq_response1_js.map((val, ind) => { return 20 * Math.log10(val); });
	// await plot_line_graph_dataObject(f, freq_response1_js_db, "Frequency response tf: decibels");

	// --------------------
	
	const series1 = freq_response1_js.map((value, index) => ({ x: index*2*Math.PI*0.02, y: value }));
	const surface = { name: 'Line chart', tab: 'Charts' };
	const data = { values: [series1], series: ['Frequency response (Hz)'] };
	tfvis.render.linechart(surface, data);

	// --------------------
	
	const series2 = freq_response1_js_db.map((value, index) => ({ x: index*2*Math.PI*0.02, y: value }));
	const surface = { name: 'Line chart', tab: 'Charts' };
	const data = { values: [series2], series: ['Frequency response (Decibels)'] };
	tfvis.render.linechart(surface, data);

	// --------------------
	
}

// -----------------------------------------------

async function audio_to_spectrogram() {
	
	const [t1, x_avg] = await audio_to_timeseries();
	
	// --------------------

	// Calculate spectrogram
	var frameLength = 255;
	var frameStep = 128;

	// Convert the waveform to a spectrogram using the Short-Time Fourier Transform (STFT)
	var spectrogram = tf.signal.stft(x_avg, frameLength, frameStep);
	console.log('spectrogram : ', spectrogram);
	// dtype: "complex64"
	// shape: Array [ 0, 129 ]
	// strides: Array [ 129 ]

	// Obtain the magnitude of the STFT (dtype: "float32")
	spectrogram = tf.abs(spectrogram);
	console.log('spectrogram : ', spectrogram);
	// dtype: "float32"
	// shape: Array [0, 129]
	// strides: Array [ 129 ]

	// Add an extra-dimension to view the results as an image
	spectrogram = spectrogram.expandDims(0);
	console.log('spectrogram : ', spectrogram);
	// dtype: "float32"
	// shape: Array(3) [ 1, 0, 129 ]
	// strides: Array [ 0, 129 ]


	const spectrogramArray = spectrogram.arraySync();

	// --------------------

	// Plot 3D data on canvas
	var w = frameLength;
	const ctx = await create_dynamic_canvasElement(w);
	
	// Manipulate image data, change the alpha component
	// Way 0: use the 4D data array
	let imageDataArray = new Uint8ClampedArray(w * w * 4);
	for (let i = 0; i < w * w; i++) {
	     let value = spectrogram.dataSync()[i];
	     imageDataArray[i * 4] = value > 0.5 ? 255 : 0; // Red component
	     imageDataArray[i * 4 + 1] = value > 0.5 ? 255 : 0; // Green component
	     imageDataArray[i * 4 + 2] = value > 0.5 ? 255 : 0; // Blue component
	     imageDataArray[i * 4 + 3] = 255; // Alpha component, set to 255 to make it fully opaque
	}

	// Print the manipulated image data on another canvas
	let imageData = new ImageData(imageDataArray, w, w);
	
	// Draw the image data onto the canvas
	ctx.putImageData(imageData, 0, 0);
}

// -----------------------------------------------
	
async function plot_line_graph_dataObject(x, y, title_text) {

	// const dataObject = [
        //     { x: 0, y: 10 },
        //     { x: 1, y: 20 },
        //     { x: 2, y: 15 },
        //     { x: 3, y: 25 },
        //     { x: 4, y: 18 }
        // ];

	console.log("x: ", x.slice(0, 10));
	console.log("y: ", y.slice(0, 10));
	
	var dataObject = [];
	for (var i=0; i<x.length; i++) {
		var obj = { x: x.at(i), y: y.at(i) };
		dataObject.push(obj);
	}
	
	const width = 1000;
	const height = 500;

	const margin = {top: 20, right: 30, bottom: 30, left: 40};
	
        const svg = d3.select("#data_display")
		.append("svg")
		.attr("class", 'line')
		.attr("width", width)
		.attr("height", height);

        const x_scale = d3.scaleLinear()
            .domain([0, d3.max(dataObject, d => d.x)], [margin.left, width - margin.right])
            .range([0, width]);

        const y_scale = d3.scaleLinear()
            .domain([0, d3.max(dataObject, d => d.y)], [height - margin.bottom, margin.top])
            .range([height, 0]);

        const line = d3.line()
            .x(d => x_scale(d.x))
            .y(d => y_scale(d.y));

        svg.append("path")
            .datum(dataObject)
            .attr("fill", "none")
            .attr("stroke", "steelblue")
            .attr("stroke-width", 2)
            .attr("d", line);

	// --------------------
	
	// Add the x-axis
	svg.append("g")
		.attr('class', 'x axis')
		// The next line moves the axis to the bottom
		.attr("transform", `translate(0, ${height - margin.bottom})`)
		.call(d3.axisBottom(x_scale));

	// --------------------
	
	// Add the y-axis
	svg.append("g")
		.attr('class', 'y-axis')
		.attr("transform", `translate(${margin.left}, 0)`)
		.call(d3.axisLeft(y_scale))
		// Add title
		.call(g => g.append("text")
			.attr("x", d3.max(dataObject, d => d.x)/2 )
			.attr("y", 15)
			.attr("fill", "currentColor")
			.attr("text-anchor", "middle")
			.style("font-size", "16px")
			.text(`Title: ${title_text}`));

	// --------------------

}

// -----------------------------------------------






// -------------------------------------------------
// IMAGE SUBFUNCTIONS
// -------------------------------------------------
async function create_dynamic_canvasElement(w) {

  	const index = 0;
  
	// Create a canvas element
	var canvasElement = document.createElement('canvas');

	// Set the width and height of the canvas
	canvasElement.width = w;
	canvasElement.height = canvasElement.width;
	      
	// Get the 2D rendering context of the canvas
	var ctx = canvasElement.getContext("2d");
	
	if (index == 0) {
		canvasElement.style.left = 40+'px';
	} else {
		let tot = index*canvasElement.width + 40;
		canvasElement.style.left = tot+'px';
	}
	
	// Add the canvas to the document body or any other desired element
	document.getElementById('data_display').appendChild(canvasElement);

	return ctx;
}

// -------------------------------------------------

	

	


// -------------------------------------------------
// AUDIO SUBFUNCTIONS
// -------------------------------------------------
async function play_sound_from_a_url(url) {
  
  var audioElement = load_audio_from_url(url, mode="nocors");

}

// -------------------------------------------------

async function play_sound_from_a_blob_object(blob_object) {

  var file_blob_object = new File ([blob_object], 'recorded_audio', {type: "audio/mp3"});
	var url_file_blob_object = URL.createObjectURL(file_blob_object);

  await play_sound_from_a_url(url_file_blob_object);

  URL.revokeObjectURL(url_file_blob_object);
  
}
  
// -------------------------------------------------

async function load_audio_from_url(url, mode="nocors") {

	// Create an AudioElement
	const audioElement = document.createElement('audio');
	
	audioElement.src = url;
	audioElement.id = "audio track";
	audioElement.autoplay = true;
	audioElement.setAttribute("controls", true);
	audioElement.setAttribute('preload', "auto");

	if (mode == "cors") {
		audioElement.setAttribute('crossOrigin', "anonymous");
	}

  	// Create an SourceElement (audioSourceNode)
	// var sourceElement = document.createElement('source');
	// sourceElement.setAttribute("src", url);
	// console.log('sourceElement: ', sourceElement);
  
	// audioElement.appendChild(sourceElement);
	
	document.getElementById('data_display').appendChild(audioElement);

	return audioElement;
}

// -------------------------------------------------

async function evaluate_audioElement() {

	// It appears that if the audioElement is in memory, these functions can be used

	// -----------------------------------------------
	
	// Create an AudioContext
	// var audioContext = new (window.AudioContext || window.webkitAudioContext)();
	// audioContext = new AudioContext();
	// OR
	var audioContext = new AudioContext();
 
	// -----------------------------------------------

	// Create an AnalyserNode: some signal information was more reliable with analyserNode than audioContext
	var analyserNode = audioContext.createAnalyser();
	// console.log('analyserNode: ', analyserNode);
	
	var channels = audioContext.channelCount;
	if (channels == undefined) { 
		channels = analyserNode.channelCount;
	}
	// console.log('channels: ', channels);
	
	var fs = audioContext.sampleRate;
	if (fs == undefined) { 
		fs = analyserNode.context.sampleRate; // 48000
	}
	// console.log('fs: ', fs);

	let time_length = analyserNode.context.currentTime;   // 354.976
	// console.log('time_length: ', time_length);

	// -----------------------------------------------

	const frameCount = fs * 2.0;
	
	var time_sample_rate_OR_timePeriod = (1/fs) * 1000; // every time_sample_rate there is a data point, 0.020833333333333333
	// console.log('time_sample_rate_OR_timePeriod: ', time_sample_rate_OR_timePeriod);

	// -----------------------------------------------
	
	return {channels: channels, fs: fs, time_length: time_length, frameCount: frameCount, time_sample_rate_OR_timePeriod: time_sample_rate_OR_timePeriod};
}

// -------------------------------------------------
  
  
  


// -------------------------------------------------
// AUDIO PRE-PROCESSING SUBFUNCTIONS
// -------------------------------------------------
async function decodeAudioData_from_binaryString_to_uint8Array(binaryString) {
	
	// -----------------------------------------------
	// Decode the binaryString response
	// -----------------------------------------------
	var character_array = binaryString.split('');
	console.log("character_array: ", character_array);
	// Array(38190) [ "�", "�", "�", "d", "\u0000", "\u0000", "\u0000", "\u0000", "\u0000", "\u0000", … ]
			
	// Map each [binary string character; a subset of binary string characters is UTF-8] as an [ASCII number; a number from 0 to number_of_characters]
	var byteArray = character_array.map((character) => { return character.charCodeAt(0); });
	console.log("byteArray: ", byteArray);
	// byteArray:  Array(38190) [ 65533, 65533, 65533, 100, 0, 0, 0, 0, 0, 0, … ]

	// The importance of this mapping is to limit the array values from 0 to 255.
	var uint8Array = new Uint8Array(byteArray);
	console.log('uint8Array: ', uint8Array);
	// uint8Array:  Uint8Array(38190) [ 253, 253, 253, 100, 0, 0, 0, 0, 0, 0, … ]

	// In some ways a uint8Array is an arrayBuffer because the size is "fixed" meaning that no more data will be appended to the array after the UTF-8 characters. And, it is a "fixed" array because the values of the array are limited to a certain range of numbers, from 0 to 255. 

	// Convert UTF-8 array [non-fixed length array] to a binary arrayBuffer [fixed-length array]
	const arrayBuffer = uint8Array.buffer;
	console.log('arrayBuffer: ', arrayBuffer);

	// Determine the length of the typedArray_arrayBuffer
	console.log('arrayBuffer.byteLength: ', arrayBuffer.byteLength);
	
	// --------------------
	
	// Convert the TypedArray into a normal array
	const normalArray = await Array.from(uint8Array);
	console.log('normalArray: ', normalArray);

	// Determine the length of the normalArray.length
	console.log('normalArray.length: ', normalArray.length);

	var arr_char = await obtain_array_characteristics(normalArray);
	console.log('arr_char: ', arr_char);

	// --------------------

	// Normalize the audio data in arrayBuffer from [-1, 1]
	// var normalArray_normalized = await normalArray.map((val, ind) => { return val/arr_char.max_amp; });  // gave wrong results
	// var normalArray_normalized = await normalArray.map((val, ind) => { return val/255; }); 
	// console.log('normalArray max min: ', [normalArray_normalized.sort().shift(), normalArray_normalized.sort().pop()])
	// RESULT: it gives a value from 0 to 2.5656... not exactly what was expected
	
	// OR

	// Try with Tensorflow library
	const tf_normalArray = tf.tensor1d(normalArray);
	var normalArray_normalized_tf = await tf_normalArray.div(tf.scalar(255));
	  
	// --------------------
	
	// Convert Tensorflow_array to Array
	const normalArray_normalized = normalArray_normalized_tf.arraySync();
	console.log('normalArray max min: ', [normalArray_normalized.sort().shift(), normalArray_normalized.sort().pop()])
	  
	// --------------------
	
	// Only for verification
	var arr_char_normalized = await obtain_array_characteristics(normalArray_normalized);
	console.log('arr_char_normalized: ', arr_char_normalized);
	
	// --------------------

	return normalArray_normalized;
}

// -----------------------------------------------

async function separate_stero_channels(normalArray_normalized) {

  // Audio files with two channels are interleaved, meaning that [channel0_datapoint0, channel1_datapoint0, channel0_datapoint1, channel1_datapoint1, ...channel0_datapointn-1, channel1_datapointn-1] 
  var channel1 = [];
	var channel2 = normalArray_normalized.map((val, ind) => {
		if (ind % 2 == 0) {
			channel1.push(val);
			return '';
		} else {
			return val;
		}
	});
	const NonEmptyVals_toKeep = (x) => x.length != 0;
	channel2 = channel2.filter(NonEmptyVals_toKeep);
  
  return [channel1, channel2];
}

// -----------------------------------------------
  
async function obtain_array_characteristics(arr) {

	var arr_char = {};
	
	arr_char.mu = await mean(arr);
	arr_char.sigma = await std(arr);

	const arr_sort = arr.sort();
	arr_char.max_val = arr_sort.at(arr.length-1);
	arr_char.min_val = arr_sort.at(0);

	// Maximum amplitude
	arr_char.max_amp = [Math.abs(arr_char.min_val), arr_char.max_val].sort().pop();
	
	return arr_char;
}
	
// -----------------------------------------------

async function sum(arr) {
	return arr.reduce((accumulator, currentValue) => accumulator + currentValue, 0);
}

// -----------------------------------------------
  
async function mean(arr) {
	return await sum(arr)/arr.length;
}

// -----------------------------------------------

async function std(arr) {
	const mu =  await mean(arr);
	// console.log('mu: ', mu);

	var arr1 = arr.map((x) => { return x-mu; });
	const summ = await sum(arr1);
	// console.log('summ: ', summ);

	const out = Math.sqrt( Math.pow(summ, 2)/arr.length );
	// console.log('out: ', out);
	
	return out;
}

// -------------------------------------------------


async function DFT(x) {

	// Discrete Fourier Transform:  1/sqrt(N) * sum_{0}^{N-1}(x(n) exp^{-j * omega * n}), where omega = 2 * pi * k/N for k=0...N-1
	const N = x.length;
	
	var x_jomega = [];
	var x_jomega_plus = [];
	var x_jomega_minus = [];
	var x_jomega_plus_accumulated = [];
	var x_jomega_minus_accumulated = [];
	
	for (var k=0; k<N; k++) {
		var arr_at_jomega = [];
		var arr_at_jomega_plus = [];
		var arr_at_jomega_minus = [];

		var real_accumulated = 0;
		var imag_plus_accumulated = 0;
		var imag_minus_accumulated = 0;
		
		for (var n=0; n<N; n++) {
			
			var omega = 2 * Math.PI * k/N;
			
			// But, there is no imaginary component (j) in JavaScript, so this direct computation can not be performed
			// For [-j * omega * n], remove the j and just say it is an imaginary component
			// arr_at_jomega.push(x.at(n) * Math.exp(-j * omega * n));
			arr_at_jomega.push(x.at(n) * Math.exp(-omega * n));
			// RESULT: I obtain a single spike, unsure if this is correct.
			
			// OR
			
			var theta = omega * n;

			// x.at(n) * Math.exp(-j * omega * n) = x.at(n) * Math.exp(-j * theta)

			// Use sin and cos equivalent equation, to calculate the imaginary component (j)
			// The math identify is: Math.exp(j * theta) = Math.cos(theta) +/- j * Math.sin(theta). 
			// +/- means plus OR minus, so there are two numerical answers.
			// For our case there is a negative sign in the exponential, so Math.exp(-j * theta) = -Math.cos(theta) +/- j * Math.sin(theta). 
			// Replace exponent with cos and sin.
			// For [j * Math.sin(theta)], remove the j and just say it is an imaginary component
			arr_at_jomega_plus.push(x.at(n) * (-Math.cos(theta) + Math.sin(theta)));
			arr_at_jomega_minus.push(x.at(n) * (-Math.cos(theta) - Math.sin(theta)));

			// OR
			
			// Break the equation down into real and imaginary parts, and sum directly instead of a vector sum at the end of the function
			real_accumulated = real_accumulated + (x.at(n) * -Math.cos(theta));
			imag_plus_accumulated = imag_plus_accumulated + (x.at(n) * Math.sin(theta));
			imag_minus_accumulated = imag_minus_accumulated + (x.at(n) * -Math.sin(theta));
		}
		// Normalize and sum across n
		x_jomega.push(1/Math.sqrt(N) * await sum(arr_at_jomega));
		// OR
		x_jomega_plus.push(1/Math.sqrt(N) * await sum(arr_at_jomega_plus));
		x_jomega_minus.push(1/Math.sqrt(N) * await sum(arr_at_jomega_minus));
		// OR
		// Normalize the accumulated sum of values across n
		x_jomega_plus_accumulated.push(1/Math.sqrt(N) * (real_accumulated + imag_plus_accumulated));
		x_jomega_minus_accumulated.push(1/Math.sqrt(N) * (real_accumulated + imag_minus_accumulated));
	}
	
	return x_jomega_minus_accumulated;
}


async function tensorflow_FFT(x) {
	
	// Discrete Fourier Transform:  1/sqrt(N) * sum_{0}^{N-1}(x(n) exp^{-j * omega * n}), where omega = 2 * pi * k/N for k=0...N-1
	const N = x.length;
	
	var real = [];
	var imag_plus = [];
	var imag_minus = [];
	
	for (var k=0; k<N; k++) {
		var real_accumulated = 0;
		var imag_plus_accumulated = 0;
		var imag_minus_accumulated = 0;
		
		for (var n=0; n<N; n++) {
			
			var omega = 2 * Math.PI * k/N;
			var theta = omega * n;
			
			// Break the equation down into real and imaginary parts, and sum directly instead of a vector sum at the end of the function
			real_accumulated = real_accumulated + (x.at(n) * -Math.cos(theta));
			imag_plus_accumulated = imag_plus_accumulated + (x.at(n) * Math.sin(theta));
			imag_minus_accumulated = imag_minus_accumulated + (x.at(n) * -Math.sin(theta));
		}
		
		// Save the [accumulated sum of real and imaginary values across n] for each k
		real.push(real_accumulated);
		imag_plus.push(imag_plus_accumulated);
		imag_minus.push(imag_minus_accumulated);
	}

	// Call the tensorflow function to compute the sum of real and imaginary values normalized: (1/Math.sqrt(N) * (real + imag_minus))
	const real_tf = tf.tensor1d(real);
	const imag_tf = tf.tensor1d(imag_minus); // it was suggested that imag_minus should be used instead of imag_plus, but both are correct
	const x_tf = tf.cast(tf.complex(real_tf, imag_tf), 'complex64');
	
	return tf.spectral.fft(x_tf);
}


// -------------------------------------------------

// Downsample time series to a [desired_sampleRate]

// -------------------------------------------------
  
</script>

</body>
</html>

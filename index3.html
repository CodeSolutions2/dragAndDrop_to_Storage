<!DOCTYPE html>
<html>
<head></head>
    
<body>

<button type="button" id="run_video_screen_capture" onclick="run_video_screen_capture()" style="display:block">run_video_screen_capture</button>

<button type="button" id="record_audio" onclick="record_audio()" style="display:block">record_audio</button>
    
<button type="button" id="stop_record_audio" style="display:block">stop_record_audio</button>

<div id="data_display" style="display:block; text-align: left; width: 600px;">

<label for="select_video">Select an video:</label> 
<input type="file" id="upload_video_file" accept="video/*" style="display:block">

<label for="select_audio">Select an audio:</label> 
<input type="file" id="upload_audio_file" accept="video/*" style="display:block">
<button type="button" id="combine_audio_video" onclick="combine_audio_video()" style="display:block">combine_audio_video</button>


<script src="https://cdn.jsdelivr.net/npm/@ffmpeg/ffmpeg@0.12.10/dist/umd/ffmpeg.min.js" crossorigin></script>
	
<script>

// -------------------------------------------------
    
async function run_video_screen_capture() {
    
    const displayMediaOptions = { video: { displaySurface: "browser", },
                                 audio: true,
                                 preferCurrentTab: true,
                                 selfBrowserSurface: "include",
                                 systemAudio: "include",
                                 surfaceSwitching: "include",
                                 monitorTypeSurfaces: "include",
                                };
    
    await navigator.mediaDevices.getDisplayMedia(displayMediaOptions)
        .then(stream => {  
		
		// This specifies the type of blob it will create for event.data
		// var options = {mimeType: "video/webm;codecs=vp8,opus"}; // save popup does not appear
		var options = {mimeType: "video/webm; audio/webm; codecs=vp8"};
		
		var mediaRecorder = new MediaRecorder(stream, options);

		// https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/dataavailable_event
		// dataavailable runs when the MediaRecorder delivers media data to your application for its use
		// When mediaRecorder.stop() is called mediaRecorder.ondataavailable is run.
		// mediaRecorder.stop() is on the interface for the user to push.
		mediaRecorder.ondataavailable = handleDataAvailable;
		
		mediaRecorder.start();
        });

}

// -------------------------------------------------
    
function handleDataAvailable(event) {
	if (event.data.size > 0) {
		// event.data = Blob { size: 105571, type: "XXX" }
		console.log('event.data: ', event.data);
		
		download_screen_recording_video(event.data);
	}
}

// -------------------------------------------------
  
function download_screen_recording_video(blob_object) {

	console.log('blob_object: ', blob_object);
	
	var url = URL.createObjectURL(blob_object);
	var a = document.createElement("a");
	document.body.appendChild(a);
	a.setAttribute('style', 'display:none');
	a.setAttribute('href', url);
	a.setAttribute('download', 'test.webm');
      
	a.click();
  
	window.URL.revokeObjectURL(url);
}

// -------------------------------------------------

// Only works in Chrome
// https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition
// var recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition || window.mozSpeechRecognition || window.msSpeechRecognition)();
    
async function run_voice_to_text() {

    var recognition = new SpeechRecognition();

    recognition.lang = "en-US";
    recognition.continuous = true;
    recognition.interimResults = true;

    recognition.onstart = () => { document.getElementById("run_voice_to_text").textContent = "Recording..."; }
    
    recognition.onresult = (event) => {
        console.log('event.results: ', event.results);
        document.getElementById("output").textContent = event.results[0][0].transcript;
    };

    recognition.start();

    recognition.onend = () => {
        document.getElementById("run_voice_to_text").textContent = "run_voice_to_text";
    };
}


// -------------------------------------------------

async function record_audio() {

	// https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder
	const MediaOptions = { audio: true };
  
    await navigator.mediaDevices.getUserMedia(MediaOptions)
        .then((stream) => {
		
		// var mediaRecorder = new MediaRecorder(stream);
		// OR
		// This specifies the type of blob it will create for event.data
		var options = {mimeType: "audio/webm"};
		var mediaRecorder = new MediaRecorder(stream, options);
            
		mediaRecorder.start();
		console.log("recorder started - mediaRecorder.state: ", mediaRecorder.state);
		document.getElementById("record_audio").style.background = "red";
		document.getElementById("record_audio").style.color = "black";

		// Way 0
		document.getElementById("stop_record_audio").onclick = () => {
			mediaRecorder.stop();
			console.log("recorder stopped - mediaRecorder.state: ", mediaRecorder.state);
			document.getElementById("record_audio").style.background = "";
			document.getElementById("record_audio").style.color = "";
		};

		// When mediaRecorder.stop() is called mediaRecorder.ondataavailable is run.
		// mediaRecorder.stop() is called when the eventlistener is called for pushing the button stop_record_audio 
		mediaRecorder.ondataavailable = handleDataAvailable_audio;
		
            
      })
      .catch((err) => { console.error(`The following error occurred: ${err}`); });

}

// -------------------------------------------------

function handleDataAvailable_audio(event) {

	console.log('event: ', event);

	// If the recorded audio has size greater than zero, save it in an array
	if (event.data.size > 0) {
		// event.data = Blob { size: 38931, type: "XXX" }
		var url = URL.createObjectURL(event.data);
		console.log('url: ', url);
	}
	document.getElementById("stop_record_audio").removeEventListener("click", handleDataAvailable_audio);

	download_audio_recording(url);
	// Works
	
	
	// play_sound(event.data);
	// Security Error: Content at https://codesolutions2.github.io/temp_repo_js_tests/index3.html may not load data from blob:https://codesolutions2.github.io/06a46a49-f1a9-4b30-b588-477fb9408453.
}

// -------------------------------------------------
  
function download_audio_recording(url) {
	
	var a = document.createElement("a");
	document.body.appendChild(a);
	a.setAttribute('style', 'display:none');
	a.setAttribute('href', url);
	a.setAttribute('download', 'test.mp3');
      
	a.click();
  
	URL.revokeObjectURL(url);
}



// -------------------------------------------------

function play_sound(blob_object) {

	var file_blob_object = new File ([blob_object], 'recorded_audio', {type: "audio/mp3"});
	var url_file_blob_object = URL.createObjectURL(file_blob_object);
	
	// Create an AudioElement
	const audioElement = document.createElement('audio');
  
	audioElement.setAttribute("controls", true);
	audioElement.setAttribute('crossOrigin', "anonymous");
	// audioElement.setAttribute('autoplay', true);
	audioElement.setAttribute('preload', "auto");
	// OR
	audioElement.setAttribute("src", url_file_blob_object);
 
	// -----------------------------------------------
 
	// Create an AudioContext
	var audioContext = new AudioContext();
 
	// -----------------------------------------------
 
	// Create an SourceElement (audioSourceNode)
	var sourceElement = document.createElement('source');
  
	sourceElement.setAttribute("src", url_file_blob_object);
 
	// -----------------------------------------------
  
	audioElement.appendChild(sourceElement);
  
	document.getElementById('data_display').appendChild(audioElement);

	URL.revokeObjectURL(url_file_blob_object);
}

// -------------------------------------------------

// The eventlistener needs to be always running, to detect which file the user selected with browse
document.getElementById("upload_audio_file").addEventListener("change", previewInput_audio, false);
var file_name_audio;
var base64_string_audio;
	
async function previewInput_audio(event) {
	
	// ---------------------
	
	// console.log("event :", event);
	// Automatic path to the audio on the PC
	// document.getElementById("file_path").innerHTML = event.srcElement.value;
	
	// ---------------------
	
	// Take the first file
	const file = event.target.files[0];  // first file in the list of selected files, better for selecting multiple files at one time
	// console.log("file :", file);

	// ---------------------
	
	// Set the file name
	// document.getElementById("file_name_audio").innerHTML = file.name;
	// OR
	file_name_audio = file.name;
	
	// ---------------------

	const reader = new FileReader();
	
	reader.onload = async function(e){
		// Save base64_string to DOM 
		// console.log("e.target.result :", e.target.result);
		// document.getElementById("base64_string_audio").innerHTML = e.target.result;
		// OR
		base64_string_audio = e.target.result;
	}
	reader.readAsDataURL(file);
}

// -------------------------------------------------

document.getElementById("upload_video_file").addEventListener("change", previewInput_video, false);
var file_name_video;
var base64_string_video;
	
async function previewInput_video(event) {
	
	const file_video = event.target.files[0];  // first file in the list of selected files, better for selecting multiple files at one time
	// console.log("file_video :", file_video);

	// ---------------------
	
	// Set the file name
	// document.getElementById("file_name_video").innerHTML = file_video.name;
	// OR
	file_name_video = file_video.name;
	
	// ---------------------

	const reader_video = new FileReader();
	
	reader_video.onload = async function(e){
		// Save base64_string to DOM 
		// console.log("e.target.result :", e.target.result);
		// document.getElementById("base64_string_video").innerHTML = e.target.result;
		// OR
		base64_string_video = e.target.result;
	}
	reader_video.readAsDataURL(file_video);
}

// -------------------------------------------------

async function fetch_file(base64_string, file_name, file_type) {
	
	await fetch(base64_string)
		.then(response => response.blob())
		.then(async function(blob_object) { 
			return new File ([blob_object], file_name, {type: file_type});
		})
		.catch(error => { document.getElementById('error').innerHTML = error; });
}

// -------------------------------------------------
	
async function combine_audio_video() {

	// [Step 0] Load library
	console.log('FFmpegWASM: ', FFmpegWASM);

	// const ffmpeg = new FFmpeg(); //  ReferenceError: FFmpeg is not defined
	// OR

	// let { createFFmpeg, fetchFile } = FFmpeg;
	// let ffmpeg = createFFmpeg();  // error

	// OR

	const ffmpeg = new FFmpegWASM.FFmpeg();


// How does one call the Object { FFmpeg: Getter, ... } FFmpeg: __esModule: true Symbol(Symbol.toStringTag): "Module" <get FFmpeg()>: function FFmpeg()

		
	await ffmpeg.load();

	// [Step 1] Load the video and audio file
	// ffmpeg.FS('writeFile', 'video.webm', await fetch_file(base64_string_video, file_name_video, "video/webm"));
	// ffmpeg.FS('writeFile', 'audio.webm', await fetch_file(base64_string_audio, file_name_audio, "audio/webm"));
	await ffmpeg.writeFile('video.webm', await fetchFile(base64_string_video));
	await ffmpeg.writeFile('audio.webm', await fetchFile(base64_string_audio));
	
	console.log('Start transcoding');

	// [Step 2] Run a ffmpeg command
        // await ffmpeg.exec(['-i', 'video.webm',  'output.mp4']);  // Convert video.webm to output.mp4
	await ffmpeg.exec('-i', 'video.webm', '-i', 'audio.webm', '-c', 'copy', 'output.webm');
	
	console.log('Complete transcoding');
	
        const data = await ffmpeg.readFile('output.webm');
	console.log('data: ', data);
	
	// const uint8Array_audio_video = new Uint8Array(data.buffer);

	// const blob_object = new Blob(uint8Array_audio_video, {type: "video/webm"});

	// download_screen_recording_video(blob_object);
};

    
</script>
</body>
</html>
